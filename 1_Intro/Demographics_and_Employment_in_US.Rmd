---
title: "Demographics and Employment in the United States"
output:
  html_document:
    keep_md: true
---

Problem 1.1 - Loading and Summarizing the Dataset
1 point possible (graded)
Load the dataset from CPSData.csv into a data frame called CPS, and view the dataset with the summary() and str() commands.

How many interviewees are in the dataset?



```{r}
library(dplyr)
library(tidyr)
library(ggplot2)
df_CPS <- tbl_df(read.csv('CPSData.csv'))
df_Metro <- read.csv('MetroAreaCodes.csv')
df_Country <- read.csv('CountryCodes.csv')

dim(df_CPS)
```
Problem 1.2 - Loading and Summarizing the Dataset
1 point possible (graded)
Among the interviewees with a value reported for the Industry variable, what is the most common industry of employment? Please enter the name exactly how you see it.


```{r}
groupy_industry <- df_CPS %>% group_by(Industry) %>% summarise(counto = n()) %>% na.omit() %>% arrange(desc(counto))
head(groupy_industry)
```
Problem 1.3 - Loading and Summarizing the Dataset
2 points possible (graded)
Recall from the homework assignment "The Analytical Detective" that you can call the sort() function on the output of the table() function to obtain a sorted breakdown of a variable. For instance, sort(table(CPS$Region)) sorts the regions by the number of interviewees from that region.

Which state has the fewest interviewees?


  unanswered  
Which state has the largest number of interviewees?

```{r}
groupy_state <- df_CPS %>% group_by(State) %>% summarise(n_interview=n()) %>% arrange(desc(n_interview))
tail(groupy_state,1)
head(groupy_state,1)


```

Problem 1.4 - Loading and Summarizing the Dataset
1 point possible (graded)
What proportion of interviewees are citizens of the United States?
```{r}
df_CPS %>% group_by(Citizenship) %>% summarise(counto=n()) %>% mutate(ratio = counto /sum(counto)*100)
```
Problem 1.5 - Loading and Summarizing the Dataset
1 point possible (graded)
The CPS differentiates between race (with possible values American Indian, Asian, Black, Pacific Islander, White, or Multiracial) and ethnicity. A number of interviewees are of Hispanic ethnicity, as captured by the Hispanic variable. For which races are there at least 250 interviewees in the CPS dataset of Hispanic ethnicity? (Select all that apply.)
```{r}
groupy_race<-df_CPS %>% group_by(Race,Hispanic) %>% summarise(counto=n()) %>% spread(Hispanic,counto)
colnames(groupy_race) <- c('Race','no_spanic','spanic')
groupy_race %>% mutate(ratio = spanic /(no_spanic+spanic)*100) %>% arrange(desc(ratio)) %>% filter(spanic>250)
```
Problem 2.1 - Evaluating Missing Values
1 point possible (graded)
Which variables have at least one interviewee with a missing (NA) value? (Select all that apply.)



```{r}
df_CPS %>% summarise_each(funs(sum(is.na(.)))) %>% gather() %>% filter(value>0)
```
Problem 2.2 - Evaluating Missing Values
1 point possible (graded)
Often when evaluating a new dataset, we try to identify if there is a pattern in the missing values in the dataset. We will try to determine if there is a pattern in the missing values of the Married variable. The function is.na(CPS$Married) returns a vector of TRUE/FALSE values for whether the Married variable is missing. We can see the breakdown of whether Married is missing based on the reported value of the Region variable with the function table(CPS$Region, is.na(CPS$Married)). Which is the most accurate:
```{r}

df_CPS$missing <- is.na(df_CPS$Married)
groupy_missing <- df_CPS %>% group_by(missing,Age) %>% summarise(counto=n())
groupy_missing
ggplot(df_CPS, aes(x=Age,fill=missing)) + geom_histogram(binwidth=1) 

```
Problem 2.3 - Evaluating Missing Values
2 points possible (graded)
As mentioned in the variable descriptions, MetroAreaCode is missing if an interviewee does not live in a metropolitan area. Using the same technique as in the previous question, answer the following questions about people who live in non-metropolitan areas.

How many states had all interviewees living in a non-metropolitan area (aka they have a missing MetroAreaCode value)? For this question, treat the District of Columbia as a state (even though it is not technically a state).


  unanswered  
How many states had all interviewees living in a metropolitan area? Again, treat the District of Columbia as a state.
```{r}
groupy_Metro<- df_CPS %>% group_by(State) %>% summarise(no_metro_area = all(is.na(MetroAreaCode))) 
print (groupy_Metro%>% filter(no_metro_area))

groupy_Metro<- df_CPS %>% group_by(State) %>% summarise(only_metro_area = all(!is.na(MetroAreaCode))) 
groupy_Metro%>% filter(only_metro_area)


```
Problem 2.4 - Evaluating Missing Values
1 point possible (graded)
Which region of the United States has the largest proportion of interviewees living in a non-metropolitan area?


Midwest
Northeast
South
West
```{r}
df_CPS %>% group_by(Region) %>% summarise(ratio_non_metro = sum(is.na(MetroAreaCode))/n()*100)
```
Problem 2.5 - Evaluating Missing Values
4.0 points possible (graded)
While we were able to use the table() command to compute the proportion of interviewees from each region not living in a metropolitan area, it was somewhat tedious (it involved manually computing the proportion for each region) and isn't something you would want to do if there were a larger number of options. It turns out there is a less tedious way to compute the proportion of values that are TRUE. The mean() function, which takes the average of the values passed to it, will treat TRUE as 1 and FALSE as 0, meaning it returns the proportion of values that are true. For instance, mean(c(TRUE, FALSE, TRUE, TRUE)) returns 0.75. Knowing this, use tapply() with the mean function to answer the following questions:

Which state has a proportion of interviewees living in a non-metropolitan area closest to 30%?


  unanswered  
Which state has the largest proportion of non-metropolitan interviewees, ignoring states where all interviewees were non-metropolitan?
```{r}
groupy_state_metro <-df_CPS %>% group_by(State) %>% summarise(ratio_non_metro = sum(is.na(MetroAreaCode))/n()) %>% arrange(desc(ratio_non_metro))
groupy_state_metro

```

Problem 3.1 - Integrating Metropolitan Area Data
2 points possible (graded)
Codes like MetroAreaCode and CountryOfBirthCode are a compact way to encode factor variables with text as their possible values, and they are therefore quite common in survey datasets. In fact, all but one of the variables in this dataset were actually stored by a numeric code in the original CPS datafile.

When analyzing a variable stored by a numeric code, we will often want to convert it into the values the codes represent. To do this, we will use a dictionary, which maps the the code to the actual value of the variable. We have provided dictionaries MetroAreaCodes.csv and CountryCodes.csv, which respectively map MetroAreaCode and CountryOfBirthCode into their true values. Read these two dictionaries into data frames MetroAreaMap and CountryMap.

How many observations (codes for metropolitan areas) are there in MetroAreaMap?


  unanswered  
How many observations (codes for countries) are there in CountryMap?

```{r}
dim(df_Metro)
dim(df_Country)
```

Problem 3.2 - Integrating Metropolitan Area Data
2 points possible (graded)
To merge in the metropolitan areas, we want to connect the field MetroAreaCode from the CPS data frame with the field Code in MetroAreaMap. The following command merges the two data frames on these columns, overwriting the CPS data frame with the result:

CPS = merge(CPS, MetroAreaMap, by.x="MetroAreaCode", by.y="Code", all.x=TRUE)

The first two arguments determine the data frames to be merged (they are called "x" and "y", respectively, in the subsequent parameters to the merge function). by.x="MetroAreaCode" means we're matching on the MetroAreaCode variable from the "x" data frame (CPS), while by.y="Code" means we're matching on the Code variable from the "y" data frame (MetroAreaMap). Finally, all.x=TRUE means we want to keep all rows from the "x" data frame (CPS), even if some of the rows' MetroAreaCode doesn't match any codes in MetroAreaMap (for those familiar with database terminology, this parameter makes the operation a left outer join instead of an inner join).

Review the new version of the CPS data frame with the summary() and str() functions. What is the name of the variable that was added to the data frame by the merge() operation?


  unanswered  
How many interviewees have a missing value for the new metropolitan area variable? Note that all of these interviewees would have been removed from the merged data frame if we did not include the all.x=TRUE parameter.
```{r}

df_CPS_M <- left_join(df_CPS,df_Metro, by=c('MetroAreaCode'='Code'))
setdiff(colnames(df_CPS_M),colnames(df_CPS))

sum(is.na(df_CPS_M$MetroArea))
```
Problem 3.3 - Integrating Metropolitan Area Data
1 point possible (graded)
Which of the following metropolitan areas has the largest number of interviewees?


Atlanta-Sandy Springs-Marietta, GA
Baltimore-Towson, MD
Boston-Cambridge-Quincy, MA-NH
San Francisco-Oakland-Fremont, CA
```{r}
df_CPS_M %>% group_by(MetroArea) %>% summarise(counto=n())%>% na.omit() %>% arrange(desc(counto))
```
Problem 3.4 - Integrating Metropolitan Area Data
2.0 points possible (graded)
Which metropolitan area has the highest proportion of interviewees of Hispanic ethnicity? Hint: Use tapply() with mean, as in the previous subproblem. Calling sort() on the output of tapply() could also be helpful here.

```{r}
df_CPS_M %>% group_by(MetroArea) %>% summarise(ratio_sp= sum(Hispanic)/n()) %>% arrange(desc(ratio_sp))
```
Problem 3.5 - Integrating Metropolitan Area Data
2.0 points possible (graded)
Remembering that CPS$Race == "Asian" returns a TRUE/FALSE vector of whether an interviewee is Asian, determine the number of metropolitan areas in the United States from which at least 20% of interviewees are Asian.
```{r}

```
